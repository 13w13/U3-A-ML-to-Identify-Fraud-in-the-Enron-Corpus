{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning to Identify Fraud in the Enron Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "#from poi_data import *\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from numpy import mean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Select what features you'll use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features_list is a list of strings, each of which is a feature name.    \n",
    "The first feature must be \"poi\".    \n",
    "features_list = ['poi','salary']    \n",
    "**You will need to use more features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = 'poi'\n",
    "\n",
    "email_features_list = [\n",
    "    'from_messages',\n",
    "    'from_poi_to_this_person',\n",
    "    'from_this_person_to_poi',\n",
    "    'shared_receipt_with_poi',\n",
    "    'to_messages',\n",
    "    ]\n",
    "    \n",
    "financial_features_list = [\n",
    "    'bonus',\n",
    "    'deferral_payments',\n",
    "    'deferred_income',\n",
    "    'director_fees',\n",
    "    'exercised_stock_options',\n",
    "    'expenses',\n",
    "    'loan_advances',\n",
    "    'long_term_incentive',\n",
    "    'other',\n",
    "    'restricted_stock',\n",
    "    'restricted_stock_deferred',\n",
    "    'salary',\n",
    "    'total_payments',\n",
    "    'total_stock_value',\n",
    "]\n",
    "\n",
    "features_list = [target_label] + financial_features_list + email_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "\n",
    "with open('final_project_dataset.pkl', 'rb') as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>bonus</th>\n",
       "      <th>email_address</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>director_fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>METTS MARK</th>\n",
       "      <td>365788</td>\n",
       "      <td>807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1061827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600000</td>\n",
       "      <td>mark.metts@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>585062</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>1740</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>702</td>\n",
       "      <td>585062</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>267102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1295738</td>\n",
       "      <td>5634343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1386055</td>\n",
       "      <td>10623258</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6680544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2660303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1586055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3942714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELLIOTT STEVEN</th>\n",
       "      <td>170941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350000</td>\n",
       "      <td>steven.elliott@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-400729</td>\n",
       "      <td>6678735</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4890344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1788391</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>NaN</td>\n",
       "      <td>764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bill.cordes@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1038185</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>651850</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>386335</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HANNON KEVIN P</th>\n",
       "      <td>243293</td>\n",
       "      <td>1045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500000</td>\n",
       "      <td>kevin.hannon@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3117011</td>\n",
       "      <td>6391065</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>5538001</td>\n",
       "      <td>32</td>\n",
       "      <td>11350</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>1617011</td>\n",
       "      <td>1035</td>\n",
       "      <td>853064</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRAMM WENDY L</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAUSEY RICHARD A</th>\n",
       "      <td>415189</td>\n",
       "      <td>1892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1868758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000</td>\n",
       "      <td>richard.causey@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-235000</td>\n",
       "      <td>2502063</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>307895</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>350000</td>\n",
       "      <td>1585</td>\n",
       "      <td>2502063</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAYLOR MITCHELL S</th>\n",
       "      <td>265214</td>\n",
       "      <td>533</td>\n",
       "      <td>227449</td>\n",
       "      <td>1092663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600000</td>\n",
       "      <td>mitchell.taylor@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3745048</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3181250</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>563798</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DONAHUE JR JEFFREY M</th>\n",
       "      <td>278601</td>\n",
       "      <td>865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>875760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800000</td>\n",
       "      <td>jeff.donahue@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-300000</td>\n",
       "      <td>1080988</td>\n",
       "      <td>...</td>\n",
       "      <td>188</td>\n",
       "      <td>765920</td>\n",
       "      <td>22</td>\n",
       "      <td>891</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>772</td>\n",
       "      <td>315068</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLISAN JR BEN F</th>\n",
       "      <td>274975</td>\n",
       "      <td>873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1272284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600000</td>\n",
       "      <td>ben.glisan@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>778546</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>384728</td>\n",
       "      <td>16</td>\n",
       "      <td>200308</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>71023</td>\n",
       "      <td>874</td>\n",
       "      <td>393818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      salary to_messages deferral_payments total_payments  \\\n",
       "METTS MARK            365788         807               NaN        1061827   \n",
       "BAXTER JOHN C         267102         NaN           1295738        5634343   \n",
       "ELLIOTT STEVEN        170941         NaN               NaN         211725   \n",
       "CORDES WILLIAM R         NaN         764               NaN            NaN   \n",
       "HANNON KEVIN P        243293        1045               NaN         288682   \n",
       "...                      ...         ...               ...            ...   \n",
       "GRAMM WENDY L            NaN         NaN               NaN         119292   \n",
       "CAUSEY RICHARD A      415189        1892               NaN        1868758   \n",
       "TAYLOR MITCHELL S     265214         533            227449        1092663   \n",
       "DONAHUE JR JEFFREY M  278601         865               NaN         875760   \n",
       "GLISAN JR BEN F       274975         873               NaN        1272284   \n",
       "\n",
       "                     loan_advances    bonus              email_address  \\\n",
       "METTS MARK                     NaN   600000       mark.metts@enron.com   \n",
       "BAXTER JOHN C                  NaN  1200000                        NaN   \n",
       "ELLIOTT STEVEN                 NaN   350000   steven.elliott@enron.com   \n",
       "CORDES WILLIAM R               NaN      NaN      bill.cordes@enron.com   \n",
       "HANNON KEVIN P                 NaN  1500000     kevin.hannon@enron.com   \n",
       "...                            ...      ...                        ...   \n",
       "GRAMM WENDY L                  NaN      NaN                        NaN   \n",
       "CAUSEY RICHARD A               NaN  1000000   richard.causey@enron.com   \n",
       "TAYLOR MITCHELL S              NaN   600000  mitchell.taylor@enron.com   \n",
       "DONAHUE JR JEFFREY M           NaN   800000     jeff.donahue@enron.com   \n",
       "GLISAN JR BEN F                NaN   600000       ben.glisan@enron.com   \n",
       "\n",
       "                     restricted_stock_deferred deferred_income  \\\n",
       "METTS MARK                                 NaN             NaN   \n",
       "BAXTER JOHN C                              NaN        -1386055   \n",
       "ELLIOTT STEVEN                             NaN         -400729   \n",
       "CORDES WILLIAM R                           NaN             NaN   \n",
       "HANNON KEVIN P                             NaN        -3117011   \n",
       "...                                        ...             ...   \n",
       "GRAMM WENDY L                              NaN             NaN   \n",
       "CAUSEY RICHARD A                           NaN         -235000   \n",
       "TAYLOR MITCHELL S                          NaN             NaN   \n",
       "DONAHUE JR JEFFREY M                       NaN         -300000   \n",
       "GLISAN JR BEN F                            NaN             NaN   \n",
       "\n",
       "                     total_stock_value  ... from_poi_to_this_person  \\\n",
       "METTS MARK                      585062  ...                      38   \n",
       "BAXTER JOHN C                 10623258  ...                     NaN   \n",
       "ELLIOTT STEVEN                 6678735  ...                     NaN   \n",
       "CORDES WILLIAM R               1038185  ...                      10   \n",
       "HANNON KEVIN P                 6391065  ...                      32   \n",
       "...                                ...  ...                     ...   \n",
       "GRAMM WENDY L                      NaN  ...                     NaN   \n",
       "CAUSEY RICHARD A               2502063  ...                      58   \n",
       "TAYLOR MITCHELL S              3745048  ...                       0   \n",
       "DONAHUE JR JEFFREY M           1080988  ...                     188   \n",
       "GLISAN JR BEN F                 778546  ...                      52   \n",
       "\n",
       "                     exercised_stock_options from_messages    other  \\\n",
       "METTS MARK                               NaN            29     1740   \n",
       "BAXTER JOHN C                        6680544           NaN  2660303   \n",
       "ELLIOTT STEVEN                       4890344           NaN    12961   \n",
       "CORDES WILLIAM R                      651850            12      NaN   \n",
       "HANNON KEVIN P                       5538001            32    11350   \n",
       "...                                      ...           ...      ...   \n",
       "GRAMM WENDY L                            NaN           NaN      NaN   \n",
       "CAUSEY RICHARD A                         NaN            49   307895   \n",
       "TAYLOR MITCHELL S                    3181250            29      NaN   \n",
       "DONAHUE JR JEFFREY M                  765920            22      891   \n",
       "GLISAN JR BEN F                       384728            16   200308   \n",
       "\n",
       "                     from_this_person_to_poi    poi long_term_incentive  \\\n",
       "METTS MARK                                 1  False                 NaN   \n",
       "BAXTER JOHN C                            NaN  False             1586055   \n",
       "ELLIOTT STEVEN                           NaN  False                 NaN   \n",
       "CORDES WILLIAM R                           0  False                 NaN   \n",
       "HANNON KEVIN P                            21   True             1617011   \n",
       "...                                      ...    ...                 ...   \n",
       "GRAMM WENDY L                            NaN  False                 NaN   \n",
       "CAUSEY RICHARD A                          12   True              350000   \n",
       "TAYLOR MITCHELL S                          0  False                 NaN   \n",
       "DONAHUE JR JEFFREY M                      11  False                 NaN   \n",
       "GLISAN JR BEN F                            6   True               71023   \n",
       "\n",
       "                     shared_receipt_with_poi restricted_stock director_fees  \n",
       "METTS MARK                               702           585062           NaN  \n",
       "BAXTER JOHN C                            NaN          3942714           NaN  \n",
       "ELLIOTT STEVEN                           NaN          1788391           NaN  \n",
       "CORDES WILLIAM R                          58           386335           NaN  \n",
       "HANNON KEVIN P                          1035           853064           NaN  \n",
       "...                                      ...              ...           ...  \n",
       "GRAMM WENDY L                            NaN              NaN        119292  \n",
       "CAUSEY RICHARD A                        1585          2502063           NaN  \n",
       "TAYLOR MITCHELL S                        300           563798           NaN  \n",
       "DONAHUE JR JEFFREY M                     772           315068           NaN  \n",
       "GLISAN JR BEN F                          874           393818           NaN  \n",
       "\n",
       "[146 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data_dict)\n",
    "#df['LOCKHART EUGENE E']\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>bonus</th>\n",
       "      <th>email_address</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>director_fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>...</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>95</td>\n",
       "      <td>87</td>\n",
       "      <td>40</td>\n",
       "      <td>126</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>112</td>\n",
       "      <td>19</td>\n",
       "      <td>45</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>102</td>\n",
       "      <td>65</td>\n",
       "      <td>93</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>84</td>\n",
       "      <td>98</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>51</td>\n",
       "      <td>60</td>\n",
       "      <td>107</td>\n",
       "      <td>21</td>\n",
       "      <td>142</td>\n",
       "      <td>64</td>\n",
       "      <td>35</td>\n",
       "      <td>128</td>\n",
       "      <td>97</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>44</td>\n",
       "      <td>60</td>\n",
       "      <td>53</td>\n",
       "      <td>60</td>\n",
       "      <td>128</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       salary to_messages deferral_payments total_payments loan_advances  \\\n",
       "count     146         146               146            146           146   \n",
       "unique     95          87                40            126             5   \n",
       "top       NaN         NaN               NaN            NaN           NaN   \n",
       "freq       51          60               107             21           142   \n",
       "\n",
       "       bonus email_address restricted_stock_deferred deferred_income  \\\n",
       "count    146           146                       146             146   \n",
       "unique    42           112                        19              45   \n",
       "top      NaN           NaN                       NaN             NaN   \n",
       "freq      64            35                       128              97   \n",
       "\n",
       "       total_stock_value  ... from_poi_to_this_person exercised_stock_options  \\\n",
       "count                146  ...                     146                     146   \n",
       "unique               125  ...                      58                     102   \n",
       "top                  NaN  ...                     NaN                     NaN   \n",
       "freq                  20  ...                      60                      44   \n",
       "\n",
       "       from_messages other from_this_person_to_poi    poi long_term_incentive  \\\n",
       "count            146   146                     146    146                 146   \n",
       "unique            65    93                      42      2                  53   \n",
       "top              NaN   NaN                     NaN  False                 NaN   \n",
       "freq              60    53                      60    128                  80   \n",
       "\n",
       "       shared_receipt_with_poi restricted_stock director_fees  \n",
       "count                      146              146           146  \n",
       "unique                      84               98            18  \n",
       "top                        NaN              NaN           NaN  \n",
       "freq                        60               36           129  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.0 Explore csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv(data_dict):\n",
    "    \"\"\" generates a csv file from a data set\"\"\"\n",
    "    fieldnames = ['name'] + data_dict.itervalues().next().keys()\n",
    "    with open('data.csv', 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for record in data_dict:\n",
    "            person = data_dict[record]\n",
    "            person['name'] = record\n",
    "            assert set(person.keys()) == set(fieldnames)\n",
    "            writer.writerow(person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Exploratory Data Analysis #\n",
      "Total number of data points: 146\n",
      "Number of Persons of Interest: 18\n",
      "Number of people without Person of Interest label: 128\n"
     ]
    }
   ],
   "source": [
    "print('# Exploratory Data Analysis #')\n",
    "data_dict.keys()\n",
    "print('Total number of data points: %d' % len(data_dict.keys()))\n",
    "num_poi = 0\n",
    "for name in data_dict.keys():\n",
    "    if data_dict[name]['poi'] == True:\n",
    "        num_poi += 1\n",
    "print('Number of Persons of Interest: %d' % num_poi)\n",
    "print('Number of people without Person of Interest label: %d' % (len(data_dict.keys()) - num_poi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Feature Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each person has 21 features available\n"
     ]
    }
   ],
   "source": [
    "all_features = data_dict['ALLEN PHILLIP K'].keys()\n",
    "print('Each person has %d features available' %  len(all_features))\n",
    "### Evaluate dataset for completeness\n",
    "missing_values = {}\n",
    "for feature in all_features:\n",
    "    missing_values[feature] = 0\n",
    "for person in data_dict.keys():\n",
    "    records = 0\n",
    "    for feature in all_features:\n",
    "        if data_dict[person][feature] == 'NaN':\n",
    "            missing_values[feature] += 1\n",
    "        else:\n",
    "            records += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print results of completeness analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Missing Values for Each Feature:\n",
      "loan_advances 142\n",
      "director_fees 129\n",
      "restricted_stock_deferred 128\n",
      "deferral_payments 107\n",
      "deferred_income 97\n",
      "long_term_incentive 80\n",
      "bonus 64\n",
      "to_messages 60\n",
      "from_poi_to_this_person 60\n",
      "from_messages 60\n",
      "from_this_person_to_poi 60\n",
      "shared_receipt_with_poi 60\n",
      "other 53\n",
      "salary 51\n",
      "expenses 51\n",
      "exercised_stock_options 44\n",
      "restricted_stock 36\n",
      "email_address 35\n",
      "total_payments 21\n",
      "total_stock_value 20\n",
      "poi 0\n"
     ]
    }
   ],
   "source": [
    "print('Number of Missing Values for Each Feature:')\n",
    "\n",
    "#sorted(missing_values.values())\n",
    "\n",
    "#for feature in all_features:\n",
    "   # print(\"%s: %d\" % (feature, sorted(missing_values.values())[feature])\n",
    "\n",
    "\n",
    "for id in sorted(missing_values, key = missing_values.get, reverse = True):\n",
    "          print(id, missing_values[id])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.T[['salary', 'to_messages', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', \n",
    "            'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses', 'from_poi_to_this_person', \n",
    "           'exercised_stock_options', 'from_messages', 'other', 'from_this_person_to_poi', 'long_term_incentive', \n",
    "            'shared_receipt_with_poi', 'restricted_stock', 'director_fees']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.T[[\"poi\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "METTS MARK              0\n",
       "BAXTER JOHN C           0\n",
       "ELLIOTT STEVEN          0\n",
       "CORDES WILLIAM R        0\n",
       "HANNON KEVIN P          1\n",
       "                       ..\n",
       "GRAMM WENDY L           0\n",
       "CAUSEY RICHARD A        1\n",
       "TAYLOR MITCHELL S       0\n",
       "DONAHUE JR JEFFREY M    0\n",
       "GLISAN JR BEN F         1\n",
       "Name: poi_True, Length: 146, dtype: uint8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['poi_True']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y['poi_True'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1=make_pipeline(SimpleImputer(),RandomForestClassifier())\n",
    "params1 = {'simpleimputer__strategy': [\"mean\",\"median\",\"constant\"]}\n",
    "grid = GridSearchCV(model1, param_grid=params1,cv=10, scoring=\"precision\")\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('simpleimputer', SimpleImputer()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('simpleimputer', SimpleImputer()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(KNNImputer(),RandomForestClassifier())\n",
    "params = {'knnimputer__n_neighbors' : [1, 2, 3, 4, 5, 6, 7, 8, 9,10]}\n",
    "grid = GridSearchCV(model, param_grid=params,cv=10, scoring=\"precision\")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.14400373, 0.12676537, 0.15305376, 0.14256613, 0.12390769,\n",
       "        0.13118653, 0.14202447, 0.14530692, 0.12879121, 0.13675358]),\n",
       " 'std_fit_time': array([0.01587662, 0.00584866, 0.01325063, 0.01459549, 0.00468568,\n",
       "        0.00527295, 0.01243206, 0.01711557, 0.01195805, 0.0098808 ]),\n",
       " 'mean_score_time': array([0.01632242, 0.01423321, 0.01686535, 0.01622648, 0.01467221,\n",
       "        0.01438899, 0.01585834, 0.01574512, 0.01389172, 0.01575861]),\n",
       " 'std_score_time': array([0.00155762, 0.00147676, 0.00178224, 0.00219775, 0.00132362,\n",
       "        0.00110601, 0.00275838, 0.00180531, 0.00084072, 0.00215367]),\n",
       " 'param_knnimputer__n_neighbors': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'knnimputer__n_neighbors': 1},\n",
       "  {'knnimputer__n_neighbors': 2},\n",
       "  {'knnimputer__n_neighbors': 3},\n",
       "  {'knnimputer__n_neighbors': 4},\n",
       "  {'knnimputer__n_neighbors': 5},\n",
       "  {'knnimputer__n_neighbors': 6},\n",
       "  {'knnimputer__n_neighbors': 7},\n",
       "  {'knnimputer__n_neighbors': 8},\n",
       "  {'knnimputer__n_neighbors': 9},\n",
       "  {'knnimputer__n_neighbors': 10}],\n",
       " 'split0_test_score': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'split1_test_score': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'split2_test_score': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'split3_test_score': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'split4_test_score': array([0.5       , 1.        , 1.        , 0.5       , 1.        ,\n",
       "        0.5       , 0.33333333, 0.33333333, 0.5       , 0.33333333]),\n",
       " 'split5_test_score': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'split6_test_score': array([1., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'split7_test_score': array([0., 0., 0., 0., 0., 1., 1., 0., 0., 1.]),\n",
       " 'split8_test_score': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'split9_test_score': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'mean_test_score': array([0.15      , 0.1       , 0.1       , 0.15      , 0.1       ,\n",
       "        0.25      , 0.13333333, 0.03333333, 0.05      , 0.13333333]),\n",
       " 'std_test_score': array([0.32015621, 0.3       , 0.3       , 0.32015621, 0.3       ,\n",
       "        0.40311289, 0.30550505, 0.1       , 0.15      , 0.30550505]),\n",
       " 'rank_test_score': array([ 2,  6,  6,  2,  6,  1,  4, 10,  9,  4], dtype=int32)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best imputer : Knn. Let's apply fit tranform and see change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_T = df.T[['salary', 'to_messages', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', \n",
    "            'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses', 'from_poi_to_this_person', \n",
    "           'exercised_stock_options', 'from_messages', 'other', 'from_this_person_to_poi', 'long_term_incentive', \n",
    "            'shared_receipt_with_poi', 'restricted_stock', 'director_fees']]\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=4)\n",
    "\n",
    "df_T_n=imputer.fit_transform(df_T.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset=pd.DataFrame(data=df_T_n, index=data_dict.keys(),columns=['salary', 'to_messages', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', \n",
    "            'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses', 'from_poi_to_this_person', \n",
    "           'exercised_stock_options', 'from_messages', 'other', 'from_this_person_to_poi', 'long_term_incentive', \n",
    "            'shared_receipt_with_poi', 'restricted_stock', 'director_fees'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>director_fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>METTS MARK</th>\n",
       "      <td>365788.00</td>\n",
       "      <td>807.00</td>\n",
       "      <td>265650.50</td>\n",
       "      <td>1061827.0</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>-320994.75</td>\n",
       "      <td>-64687.5</td>\n",
       "      <td>585062.0</td>\n",
       "      <td>94299.00</td>\n",
       "      <td>38.00</td>\n",
       "      <td>490148.25</td>\n",
       "      <td>29.00</td>\n",
       "      <td>1740.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>211868.50</td>\n",
       "      <td>702.0</td>\n",
       "      <td>585062.00</td>\n",
       "      <td>65562.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>267102.00</td>\n",
       "      <td>2241.00</td>\n",
       "      <td>1295738.00</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>-671840.75</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>10623258.0</td>\n",
       "      <td>11200.00</td>\n",
       "      <td>65.50</td>\n",
       "      <td>6680544.00</td>\n",
       "      <td>377.25</td>\n",
       "      <td>2660303.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1586055.00</td>\n",
       "      <td>1343.5</td>\n",
       "      <td>3942714.00</td>\n",
       "      <td>65382.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELLIOTT STEVEN</th>\n",
       "      <td>170941.00</td>\n",
       "      <td>606.50</td>\n",
       "      <td>823349.00</td>\n",
       "      <td>211725.0</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>-260061.75</td>\n",
       "      <td>-400729.0</td>\n",
       "      <td>6678735.0</td>\n",
       "      <td>78552.00</td>\n",
       "      <td>8.75</td>\n",
       "      <td>4890344.00</td>\n",
       "      <td>24.75</td>\n",
       "      <td>12961.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>279303.00</td>\n",
       "      <td>232.0</td>\n",
       "      <td>1788391.00</td>\n",
       "      <td>110906.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>260119.25</td>\n",
       "      <td>764.00</td>\n",
       "      <td>1819950.75</td>\n",
       "      <td>639309.5</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>452187.5</td>\n",
       "      <td>-269785.00</td>\n",
       "      <td>-150573.0</td>\n",
       "      <td>1038185.0</td>\n",
       "      <td>67085.25</td>\n",
       "      <td>10.00</td>\n",
       "      <td>651850.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>13948.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>740019.50</td>\n",
       "      <td>58.0</td>\n",
       "      <td>386335.00</td>\n",
       "      <td>84381.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HANNON KEVIN P</th>\n",
       "      <td>243293.00</td>\n",
       "      <td>1045.00</td>\n",
       "      <td>867370.00</td>\n",
       "      <td>288682.0</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>-698791.75</td>\n",
       "      <td>-3117011.0</td>\n",
       "      <td>6391065.0</td>\n",
       "      <td>34039.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>5538001.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>11350.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1617011.00</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>853064.00</td>\n",
       "      <td>89968.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRAMM WENDY L</th>\n",
       "      <td>144826.00</td>\n",
       "      <td>966.75</td>\n",
       "      <td>106154.75</td>\n",
       "      <td>119292.0</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>505000.0</td>\n",
       "      <td>-43181.00</td>\n",
       "      <td>-43446.0</td>\n",
       "      <td>9875254.0</td>\n",
       "      <td>31966.25</td>\n",
       "      <td>54.25</td>\n",
       "      <td>9779932.75</td>\n",
       "      <td>75.25</td>\n",
       "      <td>51394.00</td>\n",
       "      <td>12.5</td>\n",
       "      <td>546024.25</td>\n",
       "      <td>459.5</td>\n",
       "      <td>561557.25</td>\n",
       "      <td>119292.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAUSEY RICHARD A</th>\n",
       "      <td>415189.00</td>\n",
       "      <td>1892.00</td>\n",
       "      <td>910104.25</td>\n",
       "      <td>1868758.0</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>-398036.25</td>\n",
       "      <td>-235000.0</td>\n",
       "      <td>2502063.0</td>\n",
       "      <td>30674.00</td>\n",
       "      <td>58.00</td>\n",
       "      <td>1698947.50</td>\n",
       "      <td>49.00</td>\n",
       "      <td>307895.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>350000.00</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>2502063.00</td>\n",
       "      <td>65998.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAYLOR MITCHELL S</th>\n",
       "      <td>265214.00</td>\n",
       "      <td>533.00</td>\n",
       "      <td>227449.00</td>\n",
       "      <td>1092663.0</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>-260061.75</td>\n",
       "      <td>-242734.5</td>\n",
       "      <td>3745048.0</td>\n",
       "      <td>47075.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3181250.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>171194.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>346371.75</td>\n",
       "      <td>300.0</td>\n",
       "      <td>563798.00</td>\n",
       "      <td>65562.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DONAHUE JR JEFFREY M</th>\n",
       "      <td>278601.00</td>\n",
       "      <td>865.00</td>\n",
       "      <td>477365.75</td>\n",
       "      <td>875760.0</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>-208024.25</td>\n",
       "      <td>-300000.0</td>\n",
       "      <td>1080988.0</td>\n",
       "      <td>96268.00</td>\n",
       "      <td>188.00</td>\n",
       "      <td>765920.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>891.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>193573.50</td>\n",
       "      <td>772.0</td>\n",
       "      <td>315068.00</td>\n",
       "      <td>65562.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLISAN JR BEN F</th>\n",
       "      <td>274975.00</td>\n",
       "      <td>873.00</td>\n",
       "      <td>798335.50</td>\n",
       "      <td>1272284.0</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>-238330.75</td>\n",
       "      <td>-115937.5</td>\n",
       "      <td>778546.0</td>\n",
       "      <td>125978.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>384728.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>200308.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>71023.00</td>\n",
       "      <td>874.0</td>\n",
       "      <td>393818.00</td>\n",
       "      <td>84381.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         salary  to_messages  deferral_payments  \\\n",
       "METTS MARK            365788.00       807.00          265650.50   \n",
       "BAXTER JOHN C         267102.00      2241.00         1295738.00   \n",
       "ELLIOTT STEVEN        170941.00       606.50          823349.00   \n",
       "CORDES WILLIAM R      260119.25       764.00         1819950.75   \n",
       "HANNON KEVIN P        243293.00      1045.00          867370.00   \n",
       "...                         ...          ...                ...   \n",
       "GRAMM WENDY L         144826.00       966.75          106154.75   \n",
       "CAUSEY RICHARD A      415189.00      1892.00          910104.25   \n",
       "TAYLOR MITCHELL S     265214.00       533.00          227449.00   \n",
       "DONAHUE JR JEFFREY M  278601.00       865.00          477365.75   \n",
       "GLISAN JR BEN F       274975.00       873.00          798335.50   \n",
       "\n",
       "                      total_payments  loan_advances      bonus  \\\n",
       "METTS MARK                 1061827.0     41962500.0   600000.0   \n",
       "BAXTER JOHN C              5634343.0     41962500.0  1200000.0   \n",
       "ELLIOTT STEVEN              211725.0     41962500.0   350000.0   \n",
       "CORDES WILLIAM R            639309.5     41962500.0   452187.5   \n",
       "HANNON KEVIN P              288682.0     41962500.0  1500000.0   \n",
       "...                              ...            ...        ...   \n",
       "GRAMM WENDY L               119292.0     41962500.0   505000.0   \n",
       "CAUSEY RICHARD A           1868758.0     41962500.0  1000000.0   \n",
       "TAYLOR MITCHELL S          1092663.0     41962500.0   600000.0   \n",
       "DONAHUE JR JEFFREY M        875760.0     41962500.0   800000.0   \n",
       "GLISAN JR BEN F            1272284.0     41962500.0   600000.0   \n",
       "\n",
       "                      restricted_stock_deferred  deferred_income  \\\n",
       "METTS MARK                           -320994.75         -64687.5   \n",
       "BAXTER JOHN C                        -671840.75       -1386055.0   \n",
       "ELLIOTT STEVEN                       -260061.75        -400729.0   \n",
       "CORDES WILLIAM R                     -269785.00        -150573.0   \n",
       "HANNON KEVIN P                       -698791.75       -3117011.0   \n",
       "...                                         ...              ...   \n",
       "GRAMM WENDY L                         -43181.00         -43446.0   \n",
       "CAUSEY RICHARD A                     -398036.25        -235000.0   \n",
       "TAYLOR MITCHELL S                    -260061.75        -242734.5   \n",
       "DONAHUE JR JEFFREY M                 -208024.25        -300000.0   \n",
       "GLISAN JR BEN F                      -238330.75        -115937.5   \n",
       "\n",
       "                      total_stock_value   expenses  from_poi_to_this_person  \\\n",
       "METTS MARK                     585062.0   94299.00                    38.00   \n",
       "BAXTER JOHN C                10623258.0   11200.00                    65.50   \n",
       "ELLIOTT STEVEN                6678735.0   78552.00                     8.75   \n",
       "CORDES WILLIAM R              1038185.0   67085.25                    10.00   \n",
       "HANNON KEVIN P                6391065.0   34039.00                    32.00   \n",
       "...                                 ...        ...                      ...   \n",
       "GRAMM WENDY L                 9875254.0   31966.25                    54.25   \n",
       "CAUSEY RICHARD A              2502063.0   30674.00                    58.00   \n",
       "TAYLOR MITCHELL S             3745048.0   47075.25                     0.00   \n",
       "DONAHUE JR JEFFREY M          1080988.0   96268.00                   188.00   \n",
       "GLISAN JR BEN F                778546.0  125978.00                    52.00   \n",
       "\n",
       "                      exercised_stock_options  from_messages       other  \\\n",
       "METTS MARK                          490148.25          29.00     1740.00   \n",
       "BAXTER JOHN C                      6680544.00         377.25  2660303.00   \n",
       "ELLIOTT STEVEN                     4890344.00          24.75    12961.00   \n",
       "CORDES WILLIAM R                    651850.00          12.00    13948.50   \n",
       "HANNON KEVIN P                     5538001.00          32.00    11350.00   \n",
       "...                                       ...            ...         ...   \n",
       "GRAMM WENDY L                      9779932.75          75.25    51394.00   \n",
       "CAUSEY RICHARD A                   1698947.50          49.00   307895.00   \n",
       "TAYLOR MITCHELL S                  3181250.00          29.00   171194.25   \n",
       "DONAHUE JR JEFFREY M                765920.00          22.00      891.00   \n",
       "GLISAN JR BEN F                     384728.00          16.00   200308.00   \n",
       "\n",
       "                      from_this_person_to_poi  long_term_incentive  \\\n",
       "METTS MARK                                1.0            211868.50   \n",
       "BAXTER JOHN C                            11.0           1586055.00   \n",
       "ELLIOTT STEVEN                            1.0            279303.00   \n",
       "CORDES WILLIAM R                          0.0            740019.50   \n",
       "HANNON KEVIN P                           21.0           1617011.00   \n",
       "...                                       ...                  ...   \n",
       "GRAMM WENDY L                            12.5            546024.25   \n",
       "CAUSEY RICHARD A                         12.0            350000.00   \n",
       "TAYLOR MITCHELL S                         0.0            346371.75   \n",
       "DONAHUE JR JEFFREY M                     11.0            193573.50   \n",
       "GLISAN JR BEN F                           6.0             71023.00   \n",
       "\n",
       "                      shared_receipt_with_poi  restricted_stock  director_fees  \n",
       "METTS MARK                              702.0         585062.00       65562.00  \n",
       "BAXTER JOHN C                          1343.5        3942714.00       65382.25  \n",
       "ELLIOTT STEVEN                          232.0        1788391.00      110906.00  \n",
       "CORDES WILLIAM R                         58.0         386335.00       84381.50  \n",
       "HANNON KEVIN P                         1035.0         853064.00       89968.50  \n",
       "...                                       ...               ...            ...  \n",
       "GRAMM WENDY L                           459.5         561557.25      119292.00  \n",
       "CAUSEY RICHARD A                       1585.0        2502063.00       65998.75  \n",
       "TAYLOR MITCHELL S                       300.0         563798.00       65562.00  \n",
       "DONAHUE JR JEFFREY M                    772.0         315068.00       65562.00  \n",
       "GLISAN JR BEN F                         874.0         393818.00       84381.50  \n",
       "\n",
       "[146 rows x 19 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.T[[\"poi\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset[\"poi\"]=df.T[[\"poi\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>poi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>METTS MARK</th>\n",
       "      <td>365788.00</td>\n",
       "      <td>807.00</td>\n",
       "      <td>265650.50</td>\n",
       "      <td>1061827.0</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>-320994.75</td>\n",
       "      <td>-64687.5</td>\n",
       "      <td>585062.0</td>\n",
       "      <td>94299.00</td>\n",
       "      <td>38.00</td>\n",
       "      <td>490148.25</td>\n",
       "      <td>29.00</td>\n",
       "      <td>1740.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>211868.50</td>\n",
       "      <td>702.0</td>\n",
       "      <td>585062.00</td>\n",
       "      <td>65562.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>267102.00</td>\n",
       "      <td>2241.00</td>\n",
       "      <td>1295738.00</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>-671840.75</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>10623258.0</td>\n",
       "      <td>11200.00</td>\n",
       "      <td>65.50</td>\n",
       "      <td>6680544.00</td>\n",
       "      <td>377.25</td>\n",
       "      <td>2660303.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1586055.00</td>\n",
       "      <td>1343.5</td>\n",
       "      <td>3942714.00</td>\n",
       "      <td>65382.25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELLIOTT STEVEN</th>\n",
       "      <td>170941.00</td>\n",
       "      <td>606.50</td>\n",
       "      <td>823349.00</td>\n",
       "      <td>211725.0</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>-260061.75</td>\n",
       "      <td>-400729.0</td>\n",
       "      <td>6678735.0</td>\n",
       "      <td>78552.00</td>\n",
       "      <td>8.75</td>\n",
       "      <td>4890344.00</td>\n",
       "      <td>24.75</td>\n",
       "      <td>12961.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>279303.00</td>\n",
       "      <td>232.0</td>\n",
       "      <td>1788391.00</td>\n",
       "      <td>110906.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>260119.25</td>\n",
       "      <td>764.00</td>\n",
       "      <td>1819950.75</td>\n",
       "      <td>639309.5</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>452187.5</td>\n",
       "      <td>-269785.00</td>\n",
       "      <td>-150573.0</td>\n",
       "      <td>1038185.0</td>\n",
       "      <td>67085.25</td>\n",
       "      <td>10.00</td>\n",
       "      <td>651850.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>13948.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>740019.50</td>\n",
       "      <td>58.0</td>\n",
       "      <td>386335.00</td>\n",
       "      <td>84381.50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HANNON KEVIN P</th>\n",
       "      <td>243293.00</td>\n",
       "      <td>1045.00</td>\n",
       "      <td>867370.00</td>\n",
       "      <td>288682.0</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>-698791.75</td>\n",
       "      <td>-3117011.0</td>\n",
       "      <td>6391065.0</td>\n",
       "      <td>34039.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>5538001.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>11350.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1617011.00</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>853064.00</td>\n",
       "      <td>89968.50</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRAMM WENDY L</th>\n",
       "      <td>144826.00</td>\n",
       "      <td>966.75</td>\n",
       "      <td>106154.75</td>\n",
       "      <td>119292.0</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>505000.0</td>\n",
       "      <td>-43181.00</td>\n",
       "      <td>-43446.0</td>\n",
       "      <td>9875254.0</td>\n",
       "      <td>31966.25</td>\n",
       "      <td>54.25</td>\n",
       "      <td>9779932.75</td>\n",
       "      <td>75.25</td>\n",
       "      <td>51394.00</td>\n",
       "      <td>12.5</td>\n",
       "      <td>546024.25</td>\n",
       "      <td>459.5</td>\n",
       "      <td>561557.25</td>\n",
       "      <td>119292.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAUSEY RICHARD A</th>\n",
       "      <td>415189.00</td>\n",
       "      <td>1892.00</td>\n",
       "      <td>910104.25</td>\n",
       "      <td>1868758.0</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>-398036.25</td>\n",
       "      <td>-235000.0</td>\n",
       "      <td>2502063.0</td>\n",
       "      <td>30674.00</td>\n",
       "      <td>58.00</td>\n",
       "      <td>1698947.50</td>\n",
       "      <td>49.00</td>\n",
       "      <td>307895.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>350000.00</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>2502063.00</td>\n",
       "      <td>65998.75</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAYLOR MITCHELL S</th>\n",
       "      <td>265214.00</td>\n",
       "      <td>533.00</td>\n",
       "      <td>227449.00</td>\n",
       "      <td>1092663.0</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>-260061.75</td>\n",
       "      <td>-242734.5</td>\n",
       "      <td>3745048.0</td>\n",
       "      <td>47075.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3181250.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>171194.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>346371.75</td>\n",
       "      <td>300.0</td>\n",
       "      <td>563798.00</td>\n",
       "      <td>65562.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DONAHUE JR JEFFREY M</th>\n",
       "      <td>278601.00</td>\n",
       "      <td>865.00</td>\n",
       "      <td>477365.75</td>\n",
       "      <td>875760.0</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>-208024.25</td>\n",
       "      <td>-300000.0</td>\n",
       "      <td>1080988.0</td>\n",
       "      <td>96268.00</td>\n",
       "      <td>188.00</td>\n",
       "      <td>765920.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>891.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>193573.50</td>\n",
       "      <td>772.0</td>\n",
       "      <td>315068.00</td>\n",
       "      <td>65562.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLISAN JR BEN F</th>\n",
       "      <td>274975.00</td>\n",
       "      <td>873.00</td>\n",
       "      <td>798335.50</td>\n",
       "      <td>1272284.0</td>\n",
       "      <td>41962500.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>-238330.75</td>\n",
       "      <td>-115937.5</td>\n",
       "      <td>778546.0</td>\n",
       "      <td>125978.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>384728.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>200308.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>71023.00</td>\n",
       "      <td>874.0</td>\n",
       "      <td>393818.00</td>\n",
       "      <td>84381.50</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         salary  to_messages  deferral_payments  \\\n",
       "METTS MARK            365788.00       807.00          265650.50   \n",
       "BAXTER JOHN C         267102.00      2241.00         1295738.00   \n",
       "ELLIOTT STEVEN        170941.00       606.50          823349.00   \n",
       "CORDES WILLIAM R      260119.25       764.00         1819950.75   \n",
       "HANNON KEVIN P        243293.00      1045.00          867370.00   \n",
       "...                         ...          ...                ...   \n",
       "GRAMM WENDY L         144826.00       966.75          106154.75   \n",
       "CAUSEY RICHARD A      415189.00      1892.00          910104.25   \n",
       "TAYLOR MITCHELL S     265214.00       533.00          227449.00   \n",
       "DONAHUE JR JEFFREY M  278601.00       865.00          477365.75   \n",
       "GLISAN JR BEN F       274975.00       873.00          798335.50   \n",
       "\n",
       "                      total_payments  loan_advances      bonus  \\\n",
       "METTS MARK                 1061827.0     41962500.0   600000.0   \n",
       "BAXTER JOHN C              5634343.0     41962500.0  1200000.0   \n",
       "ELLIOTT STEVEN              211725.0     41962500.0   350000.0   \n",
       "CORDES WILLIAM R            639309.5     41962500.0   452187.5   \n",
       "HANNON KEVIN P              288682.0     41962500.0  1500000.0   \n",
       "...                              ...            ...        ...   \n",
       "GRAMM WENDY L               119292.0     41962500.0   505000.0   \n",
       "CAUSEY RICHARD A           1868758.0     41962500.0  1000000.0   \n",
       "TAYLOR MITCHELL S          1092663.0     41962500.0   600000.0   \n",
       "DONAHUE JR JEFFREY M        875760.0     41962500.0   800000.0   \n",
       "GLISAN JR BEN F            1272284.0     41962500.0   600000.0   \n",
       "\n",
       "                      restricted_stock_deferred  deferred_income  \\\n",
       "METTS MARK                           -320994.75         -64687.5   \n",
       "BAXTER JOHN C                        -671840.75       -1386055.0   \n",
       "ELLIOTT STEVEN                       -260061.75        -400729.0   \n",
       "CORDES WILLIAM R                     -269785.00        -150573.0   \n",
       "HANNON KEVIN P                       -698791.75       -3117011.0   \n",
       "...                                         ...              ...   \n",
       "GRAMM WENDY L                         -43181.00         -43446.0   \n",
       "CAUSEY RICHARD A                     -398036.25        -235000.0   \n",
       "TAYLOR MITCHELL S                    -260061.75        -242734.5   \n",
       "DONAHUE JR JEFFREY M                 -208024.25        -300000.0   \n",
       "GLISAN JR BEN F                      -238330.75        -115937.5   \n",
       "\n",
       "                      total_stock_value   expenses  from_poi_to_this_person  \\\n",
       "METTS MARK                     585062.0   94299.00                    38.00   \n",
       "BAXTER JOHN C                10623258.0   11200.00                    65.50   \n",
       "ELLIOTT STEVEN                6678735.0   78552.00                     8.75   \n",
       "CORDES WILLIAM R              1038185.0   67085.25                    10.00   \n",
       "HANNON KEVIN P                6391065.0   34039.00                    32.00   \n",
       "...                                 ...        ...                      ...   \n",
       "GRAMM WENDY L                 9875254.0   31966.25                    54.25   \n",
       "CAUSEY RICHARD A              2502063.0   30674.00                    58.00   \n",
       "TAYLOR MITCHELL S             3745048.0   47075.25                     0.00   \n",
       "DONAHUE JR JEFFREY M          1080988.0   96268.00                   188.00   \n",
       "GLISAN JR BEN F                778546.0  125978.00                    52.00   \n",
       "\n",
       "                      exercised_stock_options  from_messages       other  \\\n",
       "METTS MARK                          490148.25          29.00     1740.00   \n",
       "BAXTER JOHN C                      6680544.00         377.25  2660303.00   \n",
       "ELLIOTT STEVEN                     4890344.00          24.75    12961.00   \n",
       "CORDES WILLIAM R                    651850.00          12.00    13948.50   \n",
       "HANNON KEVIN P                     5538001.00          32.00    11350.00   \n",
       "...                                       ...            ...         ...   \n",
       "GRAMM WENDY L                      9779932.75          75.25    51394.00   \n",
       "CAUSEY RICHARD A                   1698947.50          49.00   307895.00   \n",
       "TAYLOR MITCHELL S                  3181250.00          29.00   171194.25   \n",
       "DONAHUE JR JEFFREY M                765920.00          22.00      891.00   \n",
       "GLISAN JR BEN F                     384728.00          16.00   200308.00   \n",
       "\n",
       "                      from_this_person_to_poi  long_term_incentive  \\\n",
       "METTS MARK                                1.0            211868.50   \n",
       "BAXTER JOHN C                            11.0           1586055.00   \n",
       "ELLIOTT STEVEN                            1.0            279303.00   \n",
       "CORDES WILLIAM R                          0.0            740019.50   \n",
       "HANNON KEVIN P                           21.0           1617011.00   \n",
       "...                                       ...                  ...   \n",
       "GRAMM WENDY L                            12.5            546024.25   \n",
       "CAUSEY RICHARD A                         12.0            350000.00   \n",
       "TAYLOR MITCHELL S                         0.0            346371.75   \n",
       "DONAHUE JR JEFFREY M                     11.0            193573.50   \n",
       "GLISAN JR BEN F                           6.0             71023.00   \n",
       "\n",
       "                      shared_receipt_with_poi  restricted_stock  \\\n",
       "METTS MARK                              702.0         585062.00   \n",
       "BAXTER JOHN C                          1343.5        3942714.00   \n",
       "ELLIOTT STEVEN                          232.0        1788391.00   \n",
       "CORDES WILLIAM R                         58.0         386335.00   \n",
       "HANNON KEVIN P                         1035.0         853064.00   \n",
       "...                                       ...               ...   \n",
       "GRAMM WENDY L                           459.5         561557.25   \n",
       "CAUSEY RICHARD A                       1585.0        2502063.00   \n",
       "TAYLOR MITCHELL S                       300.0         563798.00   \n",
       "DONAHUE JR JEFFREY M                    772.0         315068.00   \n",
       "GLISAN JR BEN F                         874.0         393818.00   \n",
       "\n",
       "                      director_fees    poi  \n",
       "METTS MARK                 65562.00  False  \n",
       "BAXTER JOHN C              65382.25  False  \n",
       "ELLIOTT STEVEN            110906.00  False  \n",
       "CORDES WILLIAM R           84381.50  False  \n",
       "HANNON KEVIN P             89968.50   True  \n",
       "...                             ...    ...  \n",
       "GRAMM WENDY L             119292.00  False  \n",
       "CAUSEY RICHARD A           65998.75   True  \n",
       "TAYLOR MITCHELL S          65562.00  False  \n",
       "DONAHUE JR JEFFREY M       65562.00  False  \n",
       "GLISAN JR BEN F            84381.50   True  \n",
       "\n",
       "[146 rows x 20 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict=new_dataset.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotOutlier(data_dict, feature_x, feature_y):\n",
    "    \"\"\" Plot with flag = True in Red \"\"\"\n",
    "    data = featureFormat(data_dict, [feature_x, feature_y, 'poi'])\n",
    "    for point in data:\n",
    "        x = point[0]\n",
    "        y = point[1]\n",
    "        poi = point[2]\n",
    "        if poi:\n",
    "            color = 'red'\n",
    "        else:\n",
    "            color = 'blue'\n",
    "        plt.scatter(x, y, color=color)\n",
    "    plt.xlabel(feature_x)\n",
    "    plt.ylabel(feature_y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Visualise outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'salary': 26704229.0,\n",
       " 'to_messages': 1353.5,\n",
       " 'deferral_payments': 32083396.0,\n",
       " 'total_payments': 309886585.0,\n",
       " 'loan_advances': 83925000.0,\n",
       " 'bonus': 97343619.0,\n",
       " 'restricted_stock_deferred': -7576788.0,\n",
       " 'deferred_income': -27992891.0,\n",
       " 'total_stock_value': 434509511.0,\n",
       " 'expenses': 5235198.0,\n",
       " 'from_poi_to_this_person': 40.5,\n",
       " 'exercised_stock_options': 311764000.0,\n",
       " 'from_messages': 22.75,\n",
       " 'other': 42667589.0,\n",
       " 'from_this_person_to_poi': 6.5,\n",
       " 'long_term_incentive': 48521928.0,\n",
       " 'shared_receipt_with_poi': 683.25,\n",
       " 'restricted_stock': 130322299.0,\n",
       " 'director_fees': 1398517.0,\n",
       " 'poi': False}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(PlotOutlier(data_dict, 'total_payments', 'total_stock_value'))\n",
    "print(PlotOutlier(data_dict, 'from_poi_to_this_person', 'from_this_person_to_poi'))\n",
    "print(PlotOutlier(data_dict, 'salary', 'bonus'))\n",
    "#Remove outlier TOTAL line in pickle file.\n",
    "data_dict.pop( 'TOTAL', 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Function to remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(dict_object, keys):\n",
    "    \"\"\" removes list of outliers keys from dict object \"\"\"\n",
    "    for key in keys:\n",
    "        dict_object.pop(key, 0)\n",
    "\n",
    "outliers = ['TOTAL', 'THE TRAVEL AGENCY IN THE PARK', 'LOCKHART EUGENE E']\n",
    "remove_outlier(data_dict, outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=>Remove columns   \n",
    "Maybe more outliers ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Create new feature(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 create new copies of dataset for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 add new features to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fraction(poi_messages, all_messages):\n",
    "    \"\"\" return fraction of messages from/to that person to/from POI\"\"\"    \n",
    "    if poi_messages == 'NaN' or all_messages == 'NaN':\n",
    "        return 0.\n",
    "    fraction = poi_messages / all_messages\n",
    "    return fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in my_dataset:\n",
    "    data_point = my_dataset[name]\n",
    "    from_poi_to_this_person = data_point[\"from_poi_to_this_person\"]\n",
    "    to_messages = data_point[\"to_messages\"]\n",
    "    fraction_from_poi = compute_fraction(from_poi_to_this_person, to_messages)\n",
    "    data_point[\"fraction_from_poi\"] = fraction_from_poi\n",
    "    from_this_person_to_poi = data_point[\"from_this_person_to_poi\"]\n",
    "    from_messages = data_point[\"from_messages\"]\n",
    "    fraction_to_poi = compute_fraction(from_this_person_to_poi, from_messages)\n",
    "    data_point[\"fraction_to_poi\"] = fraction_to_poi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Maybe new features ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 create new copies of feature list for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feature_list = features_list +['to_messages', 'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi','shared_receipt_with_poi', 'fraction_to_poi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 get K-best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 function using SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_best(data_dict, features_list, k):\n",
    "    \"\"\" runs scikit-learn's SelectKBest feature selection\n",
    "        returns dict where keys=features, values=scores\n",
    "    \"\"\"\n",
    "    data = featureFormat(data_dict, features_list)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "\n",
    "    k_best = SelectKBest(k=k)\n",
    "    k_best.fit(features, labels)\n",
    "    scores = k_best.scores_\n",
    "    print(scores)\n",
    "    unsorted_pairs = zip(features_list[1:], scores)\n",
    "    sorted_pairs = list(reversed(sorted(unsorted_pairs, key=lambda x: x[1])))\n",
    "    k_best_features = dict(sorted_pairs[:k])\n",
    "    print (\"{0} best features: {1}\\n\".format(k, k_best_features.keys(), scores))\n",
    "    return k_best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_recursive_best(data_dict, features_list, k):\n",
    "    \"\"\" runs scikit-learn's SelectKBest feature selection\n",
    "        returns dict where keys=features, values=scores\n",
    "    \"\"\"\n",
    "    data = featureFormat(data_dict, features_list)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "\n",
    "    rec_best = RFECV(LogisticRegression(random_state=0), step=1, min_features_to_select=k, cv=20)\n",
    "    rec_best.fit(features, labels)\n",
    "    scores = rec_best.grid_scores_\n",
    "    print(scores)\n",
    "    unsorted_pairs = zip(features_list[1:], scores)\n",
    "    sorted_pairs = list(reversed(sorted(unsorted_pairs, key=lambda x: x[1])))\n",
    "    rec_best_features = dict(sorted_pairs[:k])\n",
    "    print (\"{0} best features: {1}\\n\".format(k, rec_best_features.keys(), scores))\n",
    "    return rec_best_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_features_rec = get_recursive_best(my_dataset, my_feature_list, num_features)\n",
    "my_rec_feature_list = [target_label] + list(set(best_features_rec.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.09194988  1.61965191 10.5797683   0.47114772 24.97095225  0.86590663\n",
      "  3.794392    8.93002341  3.67201071 11.22424804  0.13828023 11.07517735\n",
      "  8.4669241  22.43775097  0.47816352  3.20830339  1.56416335  7.52919918\n",
      "  0.59119378  0.59119378  3.20830339  0.47816352  1.56416335  7.52919918\n",
      " 14.31171478]\n",
      "15 best features: dict_keys(['exercised_stock_options', 'total_stock_value', 'fraction_to_poi', 'bonus', 'restricted_stock', 'salary', 'deferred_income', 'long_term_incentive', 'total_payments', 'shared_receipt_with_poi', 'loan_advances', 'other', 'from_poi_to_this_person'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_features = get_k_best(my_dataset, my_feature_list, num_features)\n",
    "\n",
    "my_feature_list = [target_label] + list(set(best_features.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 print features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 selected features: ['fraction_to_poi', 'deferred_income', 'total_payments', 'shared_receipt_with_poi', 'salary', 'other', 'from_poi_to_this_person', 'long_term_incentive', 'bonus', 'exercised_stock_options', 'total_stock_value', 'loan_advances', 'restricted_stock']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"{0} selected features: {1}\\n\".format(len(my_feature_list) - 1, my_feature_list[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 extract the features specified in features_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, my_feature_list,sort_keys = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_rec_feature_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-5d0f58063657>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_rec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatureFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_rec_feature_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msort_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'my_rec_feature_list' is not defined"
     ]
    }
   ],
   "source": [
    "data_rec=featureFormat(my_dataset, my_rec_feature_list,sort_keys = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels, features = targetFeatureSplit(data_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 scale features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### via min-max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "robust scaler, poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = make_pipeline(MinMaxScaler(), PolynomialFeatures(),\n",
    "                      StandardScaler(),RobustScaler(),\n",
    "                      SGDClassifier(random_state=0))\n",
    "params = {\n",
    "    'polynomialfeatures__degree':[2, 3, 4,5],\n",
    "    'sgdclassifier__penalty':['l1', 'l2']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(model, param_grid=params, cv=10,scoring=\"precision\")\n",
    "\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best scale: poly degree 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features=PolynomialFeatures(5).fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Using algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please name your classifier clf for easy export below.   \n",
    "Note that if you want to do PCA or other multi-stage operations,    \n",
    "you'll need to use Pipelines. For more info:    \n",
    "http://scikit-learn.org/stable/modules/pipeline.html     \n",
    "\n",
    "Provided to give you a starting point. Try a variety of classifiers.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1  Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "g_clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2  Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_clf = Pipeline(steps=[\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('classifier', LogisticRegression(C=1e-08, class_weight='balanced', dual=False, fit_intercept=True, intercept_scaling=1, \n",
    "max_iter=100, multi_class='ovr', penalty='l2', random_state=42, solver='liblinear', tol=0.001, verbose=0))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3  K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k_clf = KMeans(n_clusters=2, tol=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "s_clf = SVC(kernel='rbf', C=1000,gamma = 0.0001,random_state = 42, class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(max_depth = 5,max_features = 'sqrt',n_estimators = 10, random_state = 42, class_weight= 'balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble  import GradientBoostingClassifier\n",
    "gb_clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf_balance = BalancedBaggingClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "pe_clf= Perceptron(max_iter=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 K Nearest Neighbor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9 SDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdg_clf = SGDClassifier(random_state=0,penalty='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.10 Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_clf = MLPClassifier(random_state=1, max_iter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 evaluate function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clf1(clf, features, labels, num_iters=1000, test_size=0.3):\n",
    "    print (clf)\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    first = True\n",
    "    for trial in range(num_iters):\n",
    "        x_train, x_test, y_train, y_test =\\\n",
    "        train_test_split(features, labels, test_size=test_size)\n",
    "        clf.fit(x_train, y_train)\n",
    "        predictions = clf.predict(x_test)\n",
    "        accuracy.append(accuracy_score(y_test, predictions))\n",
    "        precision.append(precision_score(y_test, predictions))\n",
    "        recall.append(recall_score(y_test, predictions))\n",
    "        if trial % 10 == 0:\n",
    "            if first:\n",
    "                sys.stdout.write('\\nProcessing')\n",
    "            sys.stdout.write('.')\n",
    "            sys.stdout.flush()\n",
    "            first = False\n",
    "    print (\"done.\\n\")\n",
    "    print (\"precision: {}\".format(mean(precision)))\n",
    "    print (\"recall:    {}\".format(mean(recall)))\n",
    "    print (\"accuracy:    {}\".format(mean(accuracy)))\n",
    "    return mean(precision), mean(recall), mean(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clf(clf, features, labels, num_iters=1000, test_size=0.3):\n",
    "    print (clf)\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    first = True\n",
    "    for trial in range(num_iters):\n",
    "        x_train, x_test, y_train, y_test =\\\n",
    "        train_test_split(features, labels, test_size=test_size)\n",
    "        smt = SMOTE()\n",
    "        x_train, y_train= smt.fit_sample(x_train, y_train)\n",
    "        clf.fit(x_train, y_train)\n",
    "        predictions = clf.predict(x_test)\n",
    "        accuracy.append(accuracy_score(y_test, predictions))\n",
    "        precision.append(precision_score(y_test, predictions))\n",
    "        recall.append(recall_score(y_test, predictions))\n",
    "        if trial % 10 == 0:\n",
    "            if first:\n",
    "                sys.stdout.write('\\nProcessing')\n",
    "            sys.stdout.write('.')\n",
    "            sys.stdout.flush()\n",
    "            first = False\n",
    "    print (\"done.\\n\")\n",
    "    print (\"precision: {}\".format(mean(precision)))\n",
    "    print (\"recall:    {}\".format(mean(recall)))\n",
    "    print (\"accuracy:    {}\".format(mean(accuracy)))\n",
    "    return mean(precision), mean(recall), mean(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Evaluate all functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(random_state=0)\n",
      "\n",
      "Processing....................................................................................................done.\n",
      "\n",
      "precision: 0.23935748405363144\n",
      "recall:    0.5388670634920635\n",
      "accuracy:    0.6917441860465116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.23935748405363144, 0.5388670634920635, 0.6917441860465116)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_clf(sdg_clf, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                ('classifier',\n",
      "                 LogisticRegression(C=1e-08, class_weight='balanced',\n",
      "                                    multi_class='ovr', random_state=42,\n",
      "                                    solver='liblinear', tol=0.001))])\n",
      "\n",
      "Processing......................................................................"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-f7f01ff52528>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-75-d3022f7078a6>\u001b[0m in \u001b[0;36mevaluate_clf\u001b[0;34m(clf, features, labels, num_iters, test_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     81\u001b[0m         )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         y_ = (label_binarize(output[1], np.unique(y))\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/imblearn/over_sampling/_smote.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             X_new, y_new = self._make_samples(\n\u001b[1;32m    734\u001b[0m                 \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mn_samples_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples_fit_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_samples_fit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    617\u001b[0m                 \u001b[0;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 \u001b[0;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6"
     ]
    }
   ],
   "source": [
    "evaluate_clf(l_clf, features, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "\n",
      "Processing....................................................................................................done.\n",
      "\n",
      "precision: 0.22566669463176253\n",
      "recall:    0.36255703463203465\n",
      "accuracy:    0.6404883720930231\n",
      "Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                ('classifier',\n",
      "                 LogisticRegression(C=1e-08, class_weight='balanced',\n",
      "                                    multi_class='ovr', random_state=42,\n",
      "                                    solver='liblinear', tol=0.001))])\n",
      "\n",
      "Processing............."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-be5a8ac07544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mevaluate_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mevaluate_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mevaluate_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mevaluate_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-d3022f7078a6>\u001b[0m in \u001b[0;36mevaluate_clf\u001b[0;34m(clf, features, labels, num_iters, test_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     81\u001b[0m         )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         y_ = (label_binarize(output[1], np.unique(y))\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/imblearn/over_sampling/_smote.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             X_new, y_new = self._make_samples(\n\u001b[1;32m    734\u001b[0m                 \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mn_samples_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples_fit_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_samples_fit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    617\u001b[0m                 \u001b[0;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 \u001b[0;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6"
     ]
    }
   ],
   "source": [
    "evaluate_clf(g_clf, features, labels)\n",
    "evaluate_clf(l_clf, features, labels)\n",
    "evaluate_clf(k_clf, features, labels)\n",
    "evaluate_clf(s_clf, features, labels)\n",
    "evaluate_clf(rf_clf, features, labels)\n",
    "evaluate_clf(gb_clf, features, labels)\n",
    "evaluate_clf(pe_clf, features, labels)\n",
    "evaluate_clf(knn_clf, features, labels)\n",
    "evaluate_clf(sdg_clf, features, labels)\n",
    "evaluate_clf(mlp_clf, features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Rajouter fonction print best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BalancedRandomForestClassifier(n_estimators=10, random_state=60)\n",
      "\n",
      "Processing....................................................................................................done.\n",
      "\n",
      "precision: 0.3271598568098568\n",
      "recall:    0.3166407287157287\n",
      "accuracy:    0.8321395348837208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3271598568098568, 0.3166407287157287, 0.8321395348837208)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "evaluate_clf( BalancedRandomForestClassifier(max_depth= None, n_estimators = 10, random_state = 60, max_features = 'auto')\n",
    "                           ,features,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTETomek()\n",
    "x_train, y_train= smt.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "    min_slc=MinMaxScaler()\n",
    "    std_slc = StandardScaler()\n",
    "    rob_slc= RobustScaler()\n",
    "    pol_slc=PolynomialFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_Reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_clf =Pipeline(steps=[('min_slc', std_slc),('std_slc', std_slc),('rob_slc',rob_slc),('pol_slc',pol_slc),\n",
    "                           ('logistic_Reg', logistic_Reg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models and parameters\n",
    "model = LogisticRegression()\n",
    "\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = [\"l1\",\"l2\",\"elasticnet\", \"none\"]\n",
    "c_values = np.logspace(-4, 4, 50)\n",
    "scaler=['RobustScaler','MinMaxScaler','PolynomialFeatures','StandardScaler']\n",
    "class_weight=['balanced','None']\n",
    "multi_class=[\"ovr\"]\n",
    "\n",
    "scoring = {'precision_macro': make_scorer(precision_score, average='macro'),'rec_macro': make_scorer(recall_score, average='macro'),'f1_macro': make_scorer(f1_score, average='macro')}\n",
    "\n",
    "# define grid search\n",
    "grid = dict(logistic_Reg__solver=solvers,logistic_Reg__penalty=penalty,logistic_Reg__C=c_values,logistic_Reg__class_weight=class_weight,logistic_Reg__multi_class=multi_class)\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, train_size=0.75,random_state=1)\n",
    "grid_search = GridSearchCV(estimator=l_clf, param_grid=grid, n_jobs=-1, cv=cv,scoring=scoring,refit='f1_macro',return_train_score=True)\n",
    "grid_result = grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.920741 using {'logistic_Reg__C': 0.0001, 'logistic_Reg__class_weight': 'None', 'logistic_Reg__multi_class': 'ovr', 'logistic_Reg__penalty': 'none', 'logistic_Reg__solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo=grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=algo.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions=algo.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "p=(precision_score(y_test, test_predictions))\n",
    "r=(recall_score(y_test, test_predictions))\n",
    "print(p,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_best=grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('min_slc', StandardScaler()), ('std_slc', StandardScaler()),\n",
      "                ('rob_slc', RobustScaler()), ('pol_slc', PolynomialFeatures()),\n",
      "                ('logistic_Reg',\n",
      "                 LogisticRegression(C=2222.996482526191, class_weight='None',\n",
      "                                    multi_class='ovr'))])\n",
      "\n",
      "Processing....................................................................................................done.\n",
      "\n",
      "precision: 0.21771237169263485\n",
      "recall:    0.22751132756132755\n",
      "accuracy:    0.8018604651162788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.21771237169263485, 0.22751132756132755, 0.8018604651162788)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_clf1(clf_best,features,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid1 = {'criterion': [\"gini\", \"entropy\"],\n",
    "              'max_depth':[0, 1, 2,3,4,5],\n",
    "               'min_samples_split': [0,1,2,3,4,5,6,7,8,9,10],\n",
    "               'min_samples_leaf': [0,1,2,3,4,5],\n",
    "              }\n",
    "                            \n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid=param_grid1, cv=10,scoring=\"precision\" )\n",
    "\n",
    "grid.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo=grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=algo.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ClassifierMixin.score of RandomForestClassifier(max_depth=5, min_samples_leaf=3, min_samples_split=4)>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions=algo.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=(precision_score(y_test, test_predictions))\n",
    "r=(recall_score(y_test, test_predictions))\n",
    "print(p,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid1 = { 'min_weight_fraction_leaf': [0,1,2,3,4,5,6,7] }\n",
    "grid = GridSearchCV(RandomForestClassifier(max_depth=5, min_samples_leaf=3, min_samples_split=4), param_grid=param_grid1, cv=10,scoring=\"precision\" )\n",
    "grid.fit(x_train, y_train)\n",
    "algo=grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid1 = {'max_features':[\"auto\", \"sqrt\", \"log2\"] }\n",
    "grid = GridSearchCV(RandomForestClassifier(max_depth=5, min_samples_leaf=3, min_samples_split=4,\n",
    "                       min_weight_fraction_leaf=0), param_grid=param_grid1, cv=10,scoring=\"precision\" )\n",
    "grid.fit(x_train, y_train)\n",
    "algo=grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, max_features='log2', min_samples_leaf=3,\n",
       "                       min_samples_split=4, min_weight_fraction_leaf=0)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions=algo.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.4\n"
     ]
    }
   ],
   "source": [
    "p=(precision_score(y_test, test_predictions))\n",
    "r=(recall_score(y_test, test_predictions))\n",
    "print(p,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_best=RandomForestClassifier(max_depth=5, max_features='log2', min_samples_leaf=3,\n",
    "                       min_samples_split=4, min_weight_fraction_leaf=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=5, max_features='log2', min_samples_leaf=3,\n",
      "                       min_samples_split=4, min_weight_fraction_leaf=0)\n",
      "\n",
      "Processing....................................................................................................done.\n",
      "\n",
      "precision: 0.32640056610056606\n",
      "recall:    0.4363444444444444\n",
      "accuracy:    0.8127674418604649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.32640056610056606, 0.4363444444444444, 0.8127674418604649)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_clf(clf_best,features,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid1 = { 'max_leaf_nodes': [0,1,2,3,4,5,6,\"none\"] }\n",
    "grid = GridSearchCV(RandomForestClassifier(max_depth=None, max_features='log2', min_samples_leaf=3,\n",
    "                       min_samples_split=4, min_weight_fraction_leaf=0), param_grid=param_grid1, cv=10,scoring=\"precision\" )\n",
    "grid.fit(x_train, y_train)\n",
    "algo=grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=5, max_features='log2', max_leaf_nodes=6,\n",
      "                       min_samples_leaf=3, min_samples_split=4,\n",
      "                       min_weight_fraction_leaf=0)\n",
      "\n",
      "Processing....................................................................................................done.\n",
      "\n",
      "precision: 0.3340311551193904\n",
      "recall:    0.504504365079365\n",
      "accuracy:    0.8098139534883719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3340311551193904, 0.504504365079365, 0.8098139534883719)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_best=algo\n",
    "evaluate_clf(clf_best,features,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid1 = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "                            \n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid=param_grid1, cv=10,scoring=\"precision\" )\n",
    "\n",
    "grid.fit(x_train, y_train)\n",
    "algo=grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions=algo.predict(x_test)\n",
    "p=(precision_score(y_test, test_predictions))\n",
    "r=(recall_score(y_test, test_predictions))\n",
    "print(p,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid1 = {'min_impurity_decrease': [0,1,2,3,4,5,6]}\n",
    "grid = GridSearchCV(RandomForestClassifier(max_depth=5, max_features='log2', max_leaf_nodes=6,\n",
    "                       min_samples_leaf=3, min_samples_split=4,\n",
    "                       min_weight_fraction_leaf=0),param_grid=param_grid1, cv=10,scoring=\"precision\" )\n",
    "grid.fit(x_train, y_train)\n",
    "algo=grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions=algo.predict(x_test)\n",
    "p=(precision_score(y_test, test_predictions))\n",
    "r=(recall_score(y_test, test_predictions))\n",
    "print(p,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid1 = {'min_impurity_split': [0,1,2,3,4,5,6],}\n",
    "grid = GridSearchCV(RandomForestClassifier(max_depth=5, max_features='log2', max_leaf_nodes=6,\n",
    "                       min_samples_leaf=3, min_samples_split=4,\n",
    "                       min_weight_fraction_leaf=0),param_grid=param_grid1, cv=10,scoring=\"precision\" )\n",
    "grid.fit(x_train, y_train)\n",
    "algo=grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-255-6e40cd39bc47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"precision\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    376\u001b[0m             trees = [self._make_estimator(append=False,\n\u001b[0;32m    377\u001b[0m                                           random_state=random_state)\n\u001b[1;32m--> 378\u001b[1;33m                      for i in range(n_more_estimators)]\n\u001b[0m\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m             \u001b[1;31m# Parallel loop: we prefer the threading backend as the Cython code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    376\u001b[0m             trees = [self._make_estimator(append=False,\n\u001b[0;32m    377\u001b[0m                                           random_state=random_state)\n\u001b[1;32m--> 378\u001b[1;33m                      for i in range(n_more_estimators)]\n\u001b[0m\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m             \u001b[1;31m# Parallel loop: we prefer the threading backend as the Cython code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[1;34m(self, append, random_state)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m             \u001b[0m_set_random_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\u001b[0m in \u001b[0;36m_set_random_states\u001b[1;34m(estimator, random_state)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mto_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'random_state'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__random_state'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mto_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mget_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \"\"\"\n\u001b[0;32m    204\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    176\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n\u001b[0;32m    177\u001b[0m                       if p.name != 'self' and p.kind != p.VAR_KEYWORD]\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVAR_POSITIONAL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m                 raise RuntimeError(\"scikit-learn estimators should always \"\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid1 = { 'min_weight_fraction_leaf': [0,1,2,3,4,5,6,7],\n",
    "               'max_features':[\"auto\", \"sqrt\", \"log2\"],\n",
    "                'max_leaf_nodes': [0,1,2,3,4,5,6,\"none\"],\n",
    "               'min_impurity_decrease': [0,1,2,3,4,5,6],\n",
    "               'min_impurity_split': [0,1,2,3,4,5,6],\n",
    "               'bootstrap': [\"True\", \"False\"],\n",
    "               'oob_score': [\"True\",\"False\"],\n",
    "               'class_weight': [\"balanced\", \"balanced_subsample\"] }\n",
    "                            \n",
    "grid = GridSearchCV(RandomForestClassifier(max_depth=5, min_samples_leaf=3, min_samples_split=4), param_grid=param_grid1, cv=10,scoring=\"precision\" )\n",
    "\n",
    "grid.fit(x_train, y_train)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Logistic Regression as final algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = mlp_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dump your classifier, dataset and features_list so   \n",
    "anyone can run/check your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open(\"../final_project/my_classifier.pkl\", \"wb\"))\n",
    "pickle.dump(my_dataset, open(\"../final_project/my_dataset.pkl\", \"wb\"))\n",
    "pickle.dump(my_feature_list, open(\"../final_project/my_feature_list.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Tune your classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Task 5: Tune your classifier to achieve better than .42 precision and recall   \n",
    " using our testing script. Check the tester.py script in the final project  \n",
    " folder for details on the evaluation method, especially the test_classifier   \n",
    " function. Because of the small size of the dataset, the script uses   \n",
    " stratified shuffle split cross validation. For more info:   \n",
    " http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html  \n",
    "\n",
    "Example starting point. Try investigating other evaluation techniques!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Dump your classifier, dataset, and features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6: Dump your classifier, dataset, and features_list so anyone can   \n",
    "check your results. You do not need to change anything below, but make sure  \n",
    "that the version of poi_id.py that you submit can be run on its own and   \n",
    "generates the necessary .pkl files for validating your results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
